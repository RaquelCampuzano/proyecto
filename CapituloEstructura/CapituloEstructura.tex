% !TEX root =../LibroTipoETSI.tex
\chapter{Estructura de \redborderddos}\LABCHAP{CAPEstructura}
\pagestyle{esitscCD}
% TODO Falta epígrafe
\epigraph{  FaltaFalta }{FaltaFalta}

%\lettrine[lraise=0.7, lines=1, loversize=-0.25]{E}{l} 
\lettrine[lraise=-0.1, lines=2, loversize=0.25]{R}edBorder DDoS\index{RedBorder DDoS} es el nombre del producto en el 
que, mediante el análisis del tráfico en tiempo real a través del algoritmo \gls{CUSUM}, nos permite detectar ataques 
\gls{DDoS} en tiempo real.

A lo largo de este capítulo, %TODO

\section{Alcance de \redborderddos} %TODO hablar de la escalabilidad.
Como vimos en el \CHAP{Denegacion de Servicio}, podemos diferencias los ataques de \gls{DDoS} en dos grandes bloques: 
Ataques por inundación, que buscan saturar los recursos de los que depende el servicio, y ataques semánticos. que 
buscan explotar una vulnerabilidad conocida.

\redborderddos{} intenta detectar y, en la medida de lo posible, mitigar el primer tipo de ataque, mediante el 
algoritmo \gls{CUSUM} visto en el capítulo \CHAP{Algoritmo CUSUM}. 

%TODO Falta. Relacioanr con los tipos de ataques de DDoS
\section{Nociones previas}

%TODO por qué basado en C

A lo largo de este capítulo se describirá la estructura de \redborderddos. \redborderddos{} está basado en el lenguaje 
de programación C, y usa alguna característica avanzada que no todos los usuarios de C tienen por qué conocer antes de 
leer este capítulo.

Por tanto, describiremos en esta sección las técnicas usadas, a fin de que podamos hacer referencia a ellas al 
describir el funcionamiento del programa sin necesidad de mezclar detalles de bajo y alto nivel.

\subsection{Comparación de números en coma flotante}\index{Número en coma flotante}
Salvar un número decimal en la memoria de un ordenador tiene una condición importante: La memoria del ordenador es 
finita. Los números, por el contrario, son infinitos. Es más, entre dos números distinguibles cualesquiera, hay 
infinitos números reales intermedios.

Así, pues, si destinamos por ejemplo $4$ bits de memoria para guardar un número, para una misma base sólo podremos 
guardar $2^{4}$ números distintos. Si, por ejemplo, queremos guardar los números posibles entre $0$ y $1$, la 
asignación número $\rightarrow$ representación binaria quedaría como en la \TAB{RepresentacionBinariaEjemplo4bits}.

\begin{table}
\begin{tabular}{cl}
 Representación & Número \\\hline
  \texttt{0000} & 0.000000 \\
  \texttt{0001} & 0.066667 \\
  \texttt{0010} & 0.133333 \\
  \texttt{0011} & 0.200000 \\
  \texttt{0100} & 0.266667 \\
  \texttt{0101} & 0.333333 \\
  \texttt{0110} & 0.400000 \\
  \texttt{0111} & 0.466667 \\
  \texttt{1000} & 0.533333 \\
  \texttt{1001} & 0.600000 \\
  \texttt{1010} & 0.666667 \\
  \texttt{1011} & 0.733333 \\
  \texttt{1100} & 0.800000 \\
  \texttt{1101} & 0.866667 \\
  \texttt{1110} & 0.933333 \\
  \texttt{1111} & 1.000000
 \end{tabular}
 \caption{Representación posible de flotantes equidistantes desde el 0 hasta el 1 usando cuatro bits.}
 \LABTAB{RepresentacionBinariaEjemplo4bits}
\end{table}

Si, con esta representación, computamos $1/4+1/4-1/2$, el ordenador tendría que aproximarlo a 
$\mathtt{0b0100}+\mathtt{0b0100}-\mathtt{0b0111} \rightarrow 0.266667+0.266667-0.466667$, las representaciones más 
próximas de las que disponemos. Entonces, el resultado de la operación binaria sería $\mathtt{0b0001} \rightarrow 
0.066667$, y no $0$, como se esperaría en un sistema numérico real.

Pese a que en el proyecto se trabaja con números en punto flotante IEE754 dobles, capaces de almacenar $2^64$ números 
distintos, no estamos exentos de este tipo de fallos. Para evitarlos, la comparación entre números no debe ser 
realizada con el operador \texttt{==}, sino que en su lugar se compararán dejando lugar a un margen de error, como se 
ve en Algoritmo \ALG{ComparacionFlotante}.

\begin{algorithm}
 \KwData{Dos números $n_1$,$n_2$ en formato \texttt{double IEEE754}, y un epsilon $e$}
 \KwResult{Comparación de los mismos: 0 si son iguales, $>0$ si $n_1>n_2$ y $<0$ en otro caso}
 \eIf{$abs\left(n_1-n_2\right)< e$}{
   devolver 0\;
 }{
   devolver $n_1-n_2$\;
 }
 \caption{Algoritmo de comparación de números en punto flotante}
 \LABALG{ComparacionFlotante}
\end{algorithm}


\subsection{Estructuras de datos básicas}\index{Estructura de datos}
Para almacenar el funcionamiento de cada flujo de tráfico, y ser capaz de compararlo con el supuesto funcionamiento 
normal de la red, es necesario contar con unos sistemas de almacenamiento rápidos y eficientes. Si se pierde demasiado 
tiempo en el manejo de la memoria, \redborderddos{} no será capaz de leer y modelar el tráfico a una velocidad 
correcta, y a la larga no será capaz de detectar nada.

A lo largo de esta subsección describiremos las estructuras de almacenamiento de datos usadas en el programa. Una vez 
que conozcamos el funcionamiento de estas, será más fácil ver el sistema como un todo, y abstraer correctamente cada 
una de sus partes.

\subsubsection{Vector de memoria}\index{Vector}\LABSSSEC{VectorMemoria}
Un vector consiste en una o más celdas de memoria situadas de una forma contigua. Esto es, si cada elemento del vector 
ocupa $L$ bytes, y el vector comienza en la dirección de memoria $M$, podemos acceder al tercer elemento del vector en 
la dirección $M+3L$.

El vector tiene un tamaño fijo conocido en el momento de su creación, y, a lo largo de este trabajo, no variará. Hemos 
de tener precaución al acceder a las distintas posiciones del vector: si hemos reservado memoria para $K$ elementos, y 
accedemos al elemento número $J>=K$\footnote{En C, las posiciones del vector empiezan en 0. Si accedemos al elemento 
$K$, ya estamos accediendo a memoria fuera del vector}, esa zona de memoria no está dentro del vector, y no se puede 
saber qué habrá.

\subsubsection{Listas enlazadas}\index{Lista Enlazada}\LABSSSEC{ListaEnlazada}
Si, tras haber definido un tamaño de vector, queremos añadir nuevos elementos, deberíamos redimensionar el espacio 
reservado del vector en memoria. Esta es una operación costosa, ya que puede no existir espacio contiguo al final o 
principio del vector, y necesitar buscar un espacio contiguo más grande. Tras encontrarlo, se necesitará copiar todos 
los elementos del vector, y pueden ser muchos.

Aún peor, ¿qué ocurre cuando queremos insertar un elemento en mitad del vector? Es necesario mover todos los elementos 
desde la posición requerida hasta el final del vector una unidad, y después insertar ese último elemento, lo que 
resulta inadmisible.

% TODO describir NULL en el glosario?
Para solucionar este problema, podemos usar una lista tipo enlazada. En ella, cada elemento tiene un puntero que apunta 
al siguiente elemento, mientras que el último elemento de la lista siempre apuntará a NULL. Por lo tanto, insertar o 
eliminar un elemento en mitad de la lista sólo requeriría localizar el elemento anterior, y modificar dos puntero. Como 
caso especial está el insertado de elementos a la cabeza de la lista, que sólo requiere modificar dos punteros.

Podemos ver en la \FIG{EstructuraLinkedList} la estructura que tendría.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.5\textwidth]{CapituloEstructura/Figuras/EstructuraListaEnlazada-crop}
\caption{Estructura de una lista enlazada}
\LABFIG{EstructuraLinkedList} %Esto es una forma propia de los autores de gestionar las etiquetas y referencias
\end{figure}
%

Sin embargo, el acceso aleatorio a un elemento de la lista enlazada es algo más costoso, ya que para acceder la 
posición $N$ es necesario iterar por todos los $N-1$ elementos. Existen otras variantes, que incluyen usar un puntero 
al anterior y posterior nodo, listas circulares, listas con puntero a la cabeza y a cola, etc. Pero por el momento, nos 
basta con esta visión de las listas enlazadas.

%TODO explicar listas doblemente enlazadas, y la lista tommy.

\subsubsection{Pilas}\index{Pila}
Una pila es una estructura de datos con sólo dos operaciones: añadir elementos a la pila (operación \emph{push}) y 
extraer el último elemento de la pila (operación \emph{pop}). Si insertamos un elemento $E$, insertamos tras él $N$ 
elementos, será necesario extraer (\emph{pop}) los $N$ elementos antes de volver a acceder al elemento $E$. Es, por 
tanto, una cola \gls{LIFO}.

Podemos simular una pila con un vector de memoria, si llevamos la cuenta de los elementos que hemos insertado con una 
variable \emph{cuenta} con valor inicial a cero, podemos hacer \emph{push} salvando en dicha posición e incrementando 
esa variable, y \emph{pop} decrementandola y devolviendo la posición.

\subsubsection{Tabla HASH}\index{Tabla HASH}
Resumiendo los apartados \SSSEC{VectorMemoria} y \SSSEC{ListaEnlazada}:
\begin{itemize}
 \item Es muy rápido acceder a una posición dada de un vector, pero la inserción de elementos es potencialmente muy 
lenta. Además, mientras el vector no está lleno, desperdicias memoria
 \item El acceso aleatorio a un elemento de una lista enlazada es lento. Sin embargo, la inserción de elementos en 
cualquier punto es rápida, especialmente al principio, y no se desperdicia memoria.
\end{itemize}

La tabla HASH pretende aunar lo mejor de ambas estructuras. Una tabla HASH es un mapa asociativo, en el que cada 
\emph{valor} $V$ tiene asociada una \emph{clave} $K$ por la que puede ser buscado, y dicha clave determina una posición 
en un vector de memoria.

Internamente, el vector de memoria tiene $S$ posiciones, donde $S$ es una potencia de 2.Cada posición es una lista de 
elementos del mismo tipo que el valor que queremos almacenar.

\begin{figure}[hbtp]
\centering
%\hfill
\subfloat[Diagrama de Actividad de Inserción]%
   {\LABFIG{InsertarTablaHash}%
   \includegraphics[width=0.48\textwidth]{CapituloEstructura/Figuras/ActividadFuncionInsertarTablaHash-crop}}%
\hfill
\subfloat[Diagrama de actividad de Búsqueda]%
 {\LABFIG{BuscarTablaHash}%
 \includegraphics[width=0.48\textwidth]{CapituloEstructura/Figuras/ActividadFuncionBuscarTablaHash-crop}}%
%
\caption{Diagrama de Actividad de las operaciones a realizar sobre una tabla HASH}
\end{figure}
%

A la hora de almacenar un elemento $E_0$ con clave $K_0$, a la clave se le aplica una máscara que asegure un número 
inferior a $S$: Por ejemplo, si $S$ es $2^8$, la máscara debe ser $M=0xff$, de forma que la operación \emph{AND} bit a 
bit de siempre $P_0=K_0\&S<2^8$. El elemento $E_0$ es entonces insertado en la lista que ocupa la posición $P_0$ del 
vector de memoria. El diagrama de actividad de esta función se puede ver en \FIG{InsertarTablaHash}.

Por su parte, a la hora de recuperar el elemento, volvemos a aplicar la máscara a la clave, $P_0=K_0\&M$, y buscamos en 
la lista enlazada que ocupa la posición $P_0$ del vector. Esta vez, sí deberemos comparar los elementos con la clave 
$K$, ya que en ella existen todos los elementos insertados cuyas claves $K$ cumplan $K\&M=P_0$. Podemos ver su diagrama 
de actividad en \FIG{BuscarTablaHash}.

Para conseguir la mínima probabilidad de colisión, se le aplica a las diferentes claves una función HASH\index{Función 
HASH}, esto es una, función que ante la misma entrada de siempre la misma salida, pero que pequeñas diferencias de los 
valores de la entrada provoca grandes diferencias en los valores de salida. Como nota, es probable que una función HASH 
produzca colisiones, esto es, diferentes entradas producen la misma salida.

En el mismo sentido, es importante encontrar una buena relación entre el tamaño de la tabla hash y el número de 
elementos que queremos insertar. Siempre será más rápido que una lista puramente enlazada, pero cuantos menos elementos 
ocupen la misma posición de memoria, mejor.

%TODO reservar una sección "pruebas realizadas"

Por ejemplo, supongamos que queremos almacenar unos contadores, cuyo flujo está asociado a la \gls{IP} \emph{10.0.1.1}, 
en una tabla hash de longitud $S=2^8$. Tras aplicarle nuestra función HASH, vemos que 
$\text{hash}(\text{10.0.0.1})=476$. Buscamos en la tabla HASH la lista enlazada de la posición 
$476\&0xff=220$, y la añadimos a la cola. Ver \FIG{EstadoTablaHashInsercion} para visualizar gráficamente qué ocurre 
con la tabla HASH.

\begin{figure}[hbtp]
\centering
\subfloat[Estado antes de la inserción]%
   {\begin{minipage}[t]{0.47\textwidth}\vspace{0pt}
    \includegraphics[width=\textwidth]{CapituloEstructura/Figuras/TablaHashAntesInsercion-crop}%
    \end{minipage}}
\hfill
\subfloat[Estado después de la inserción]%
 {\begin{minipage}[t]{0.47\textwidth}\vspace{0pt}
 \includegraphics[width=\textwidth]{CapituloEstructura/Figuras/TablaHashDespuesInsercion-crop}%
  \end{minipage}}
%
\caption{Inserción de un elemento en la tabla HASH}
\LABFIG{EstadoTablaHashInsercion}
\end{figure}

\subsection{Programación multihilo}\LABSSEC{ProgramacionMultihilo}
Un hilo de un proceso\index{Hilo}, también llamado proceso ligero\index{Proceso Ligero}, es una forma que tienen las 
aplicaciones de ejecutar código de manera concurrente. 

Al crear un hilo, se crea una nueva entrada en el planificador\index{Planificador} del \gls{SO}, y ésta instancia se 
ejecutará con la misma prioridad que otros procesos. Tendrá su propio contador de programa\footnote{Indicador del punto 
de ejecución actual.}, su propia pila de llamada a funciones y su propio estado de CPU, lo que permite que el hilo 
llamante y el llamado se ejecuten por separado.

Sin embargo, los distintos hilos de un proceso comparten el espacio de direcciones y ficheros abiertos. Esto es útil 
para compartir memoria entre ellos, pero genera la necesidad de un mecanismo de sincronización.

Por ejemplo, supongamos una función que realiza las siguientes acciones sobre un entero de valor 0:
\begin{enumerate}
 \item Copia un entero a un registro\label{item:EjemploHilosGetInt}.
 \item Incrementa ese entero.
 \item Vuelve a guardar ese entero en su ubicación original, ya incrementado.
\end{enumerate}

Esta función se está llamando concurrentemente\index{Concurrencia} desde dos hilos distintos. Se debería esperar que, 
tras la ejecución de los dos hilos, el entero valga 2.

Sin embargo, si hilamos mas fino, descubrimos un problema. Pongamos el caso de que, en el momento de terminar la 
instrucción \ref{item:EjemploHilosGetInt}, el planificador decide que es hora de pasar el control al hilo dos. 
Éste lee la variable (de valor 0), la incrementa, y guarda un 1. Ahora, cuando el control vuelve al hilo 1, este 
simplemente tiene en su registro un 0, lo incrementará a 1, y guardará un 1. Y no podemos saber cuando el planificador 
decidirá cambiar el hilo en ejecución, por lo que este problema se puede reproducir de manera aleatoria.

Es necesaria una \emph{Variable Cerrojo}\index{Variable Cerrojo}\index{Mutex}. Una variable especial que sólo puede ser 
modificada por un proceso al mismo tiempo en todo el sistema y, por tanto, proteja la \emph{sección 
crítica}\index{Sección Crítica}, esto es, aquella susceptible de ser indeterminada si el procesador cambia de hilo de 
ejecución en el momento que está siendo ejecutada.

Por tanto, la función pasaría a ser:
\begin{enumerate}
 \item Cerramos la variable cerrojo
 \item Copia un entero a un registro
 \item Incrementa ese entero.
 \item Vuelve a guardar ese entero en su ubicación original, ya incrementado.
 \item Abrimos la variable cerrojo
\end{enumerate}

De esta forma, ambos hilos de ejecución saben cuando otro proceso está modificando la \emph{región crítica}.

No obstante, esto tiene una desventaja: el hilo que espera a que la variable cerrojo sea abierta no puede hacer otra 
cosa que no sea esperar. Por tanto, una mala elección de secciones críticas hará el programa lento.

\subsection{Señales en linux. La señal SIGALRM.}\LABSSEC{SIGALRM}\index{SIGALRM}\index{Señal Linux}
Un mecanismo de comunicación entre procesos o \gls{IPC} es el envío de señales. Por ejemplo, cuando un programa intenta 
escribir en un área de memoria restringida, el \gls{SO} le envía una señal \gls{SIGSEGV}, y el proceso puede actuar en 
consecuencia.

Cuando un proceso la recibe, pueden ocurrir tres cosas según la señal. Por defecto, o es ignorada, o abortará el 
programa. No obstante, también es posible escribir código para manejar algunas señales.

En este caso, cuando el proceso decida crear un manejador para una señal\index{Manejador de señal Linux} concreta, y 
reciba dicha señal, será interrumpido y será como si en ese momento hubiese llamado al manejador. Cuando el manejador 
termine, el programa seguirá su ejecución normal. Si el programa estaba en un \texttt{sleep}, este será interrumpido, y 
el programa no dormirá los segundos restantes.

Por ejemplo, si pulsamos \texttt{Ctrol-Z} en un programa, este detendrá su ejecución y podremos o bien enviarlo a 
segundo plano con el comando \texttt{bg} o reanudar su ejecución con \texttt{fg}. Esto es notificado al programa con 
una señal \gls{SIGTSTP}, y es posible manejarla.

Por ejemplo, el \lstlistingname{} \ref{code:dumbSignalStopHandling} muestra un ejemplo de manejo de esta señal. Sin 
embargo si varias señales llegan muy rápido, comenzaremos a manejar una señal mientras aún estábamos manejando la 
anterior, por lo que tenemos el mismo problema que en \SSEC{ProgramacionMultihilo}. Para colmo, no podemos solucionarlo 
con una variable cerrojo: \gls{pthreads}\index{Librería phtread} establece que el resultado de bloquear una señal 
bloqueada por tu mismo hilo de ejecución es indeterminado. Y esto podría pasar si el manejador de la señal salta en la 
región crítica.

\begin{lstlisting}[language=C++,caption={Manejo ingenuo de la señal \gls{SIGTSTP}}, 
breaklines=true, label=code:dumbSignalStopHandling,numbers=left,float=htbp]
#include <signal.h>
#include <stdio.h>

#define N 10
static int i = 0;
static int salir = 0;

static void manejador(int signo){
    if(i++<N)
        printf("¡No quiero parar!\n");
    else
        salir = 1;
}

int main(void) {
     signal(SIGTSTP, manejador);
     while (!salir)
         sleep(1);
     return 0;
}
\end{lstlisting}

Así pues, la solución pasa por reducir al mínimo la responsabilidad del manejador de la señal: Este sólo establecerá un 
indicador global de que la señal ha sido recibida, y el manejador real estará en un hilo y, por tanto, en un entorno 
controlado. Vemos un ejemplo de este modo de proceder en \lstlistingname{} \ref{code:SignalStopHandling}

\begin{lstlisting}[language=C++,caption={Manejo de la señal \gls{SIGTSTP}}, 
breaklines=true, label=code:SignalStopHandling,numbers=left,float=htbp]
#include <signal.h>
#include <stdio.h>

#define N 10
static int sig = 0;

static void manejador(int signo){
    sig = 1;
}

int main(void) {
     int i = 0;
     signal(SIGTSTP, manejador);
     while (i<N){
        sleep(1);
        if(sig){
            printf("¡No quiero salir!\n");
            ++i;
            sig = 0;
        }
    }
    return 0;
}
\end{lstlisting}

Por último, una señal interesante, y que usaremos en el proyecto, es la señal \gls{SIGALRM}\index{Señal 
\texttt{SIGALRM}}. Mediante la función \texttt{alarm(int s)}\index{Función \texttt{alarm}}, se le notifica al \gls{SO} 
de que se desea recibir una señal \gls{SIGALRM} pasados \texttt{s} segundos. Por tanto, se podría usar para realizar 
tareas periódicas. Por ejemplo, el \lstlistingname{} \ref{code:AlarmSignal} imprimirá la fecha actual\footnote{En 
formato \emph{UNIX time}\index{UNIX time}, esto es, segundos transcurridos desde el 1 de Enero de 1970} y un mensaje 
indicativo de que se está realizando alguna tarea.

\begin{lstlisting}[language=C++,caption={Ejemplo de uso de \gls{SIGALRM}}, 
breaklines=true, label=code:AlarmSignal,numbers=left,float=htbp]
#include <signal.h>
#include <stdio.h>
#include <time.h>   // time()
#include <unistd.h> // alarm()

static int alarma = 0;

static void manejador(int signo){
    alarma = 1;
    alarm(1); // Programamos la siguiente alarma
}

int main(void) {
     signal(SIGALRM, manejador);
     alarm(1);
     while (1){
        sleep(1);
        if(alarma){
            printf("[%d] Estoy haciendo cosas...\n",time(NULL));
            // Sleep(100)
            alarma = 0;
        }
    }
    return 0;
}
\end{lstlisting}

Sin embargo, este programa vuelve a ignorar la concurrencia. ¿Qué ocurre si el programa tarda mas de la cuenta en 
ejecutarse? Si des-comentamos el \texttt{sleep(100)} entre el \texttt{printf(...)} y el \texttt{alarma = 0}, vemos que 
el programa imprime el mensaje cada dos segundos, en lugar de cada segundo. Esto es debido a que se ha lanzado la 
alarma mientras se estaba ejecutando el trabajo (el \texttt{sleep}), y nada ha cambiado tras ello (ya que sólo hemos 
establecido \texttt{alarma} a 1, pero ya estaba a 1). Debido a ello, es posible que el trabajo no se esté ejecutando 
con la periodicidad que nosotros creemos.

Para solucionarlo, se hace necesario otra variable que indique que una señal ha llegado mas tarde de la cuenta. En 
\lstlistingname{} \ref{code:AlarmSignalAcumulados}. 

Por último, no se debe confiar en hacer de \texttt{acumulados} un contador, ya que la alarma podría saltar en cualquier 
momento entre el \texttt{if(acumulados)} y el \texttt{acumulados=0}. Es necesario confiar en otros sistemas, como 
almacenar la marca de tiempo en la que el proceso fue lanzado.

\begin{lstlisting}[language=C++,caption={Ejemplo de uso de \gls{SIGALRM} con detección de pérdidas}, breaklines=true, 
label=code:AlarmSignalAcumulados,numbers=left,float=htbp]
#include <signal.h>
#include <stdio.h>
#include <time.h>   // time()
#include <unistd.h> // alarm()

static int alarma = 0;
static int acumulados = 0;

static void manejador(int signo){
    if(alarma)
        acumulados = 1; // Aún no ha acabado el anterior trabajo
    alarma = 1;
    alarm(1); // Programamos la siguiente alarma
}

int main(void) {
     signal(SIGALRM, manejador);
     alarm(1);
     while (1){
        sleep(1);
        if(alarma){
            if(acumulados){
                printf("[%d] Nos hemos saltado alguna iteración.",time(NULL));
                printf(" Se actuará en consecuencia.\n");
                acumulados = 0;
            }
            printf("[%d] Estoy haciendo cosas...\n",time(NULL));
            sleep(100);
            alarma = 0; // Todo vuelve a la normalidad
        }
    }
    return 0;
}
\end{lstlisting}

\section{Vista externa}\LABSEC{Vista Externa}
\subsection{Situación física de \redborderddos}
Desde el punto de vista de la arquitectura de red, \redborderddos{} debe colocarse en dos puertos SPAN\index{Puerto 
SPAN} del conmutador que llegue al activo protegido, tal y como muestra la \FIG{diagramaArquitectura}. Cada uno de los 
puertos SPAN clonará los paquetes dirigidos hacia el activo a proteger, y los paquetes desde el activo a proteger 
respectivamente, y los enviará hacia \redborderddos.

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{CapituloEstructura/Figuras/DiagramaArquitectura-crop}
\caption{Diagrama de Arquitectura de \redborderddos}
\LABFIG{diagramaArquitectura} %Esto es una forma propia de los autores de gestionar las etiquetas y referencias
\end{figure}
%

Tras el conmutador, se debería colocar un cortafuegos o \gls{IPS}, que se usa para:
\begin{enumerate}
 \item Detener el tráfico detectado como atacante por \redborderddos.
 \item Detener ataques semánticos o usuarios no autorizados.
\end{enumerate}

\redborderddos{} puede funcionar sin el cortafuegos\index{Cortafuegos}. No obstante, en ese caso sólo detectaremos los 
ataques, en lugar de detenerlos efectivamente.

Es necesario que \redborderddos{} se coloque delante del elemento que corta el tráfico. De otra forma, sería imposible 
para el sistema conocer cuándo ha cesado el ataque, y cuándo podemos dejar el Modo Alerta.

Podemos ver en el diagrama que podríamos multiplicar los puertos de SPAN. Esto es, si tenemos demasiado tráfico y no es 
posible enviarlo todo por un sólo puerto, podemos dedicar a \redborderddos{} dos puertos de entrada y dos de salida. 
Incluso, podríamos dedicar dos o más puertos de entrada, y sólo uno de tráfico saliente, si el tráfico que tenemos es 
altamente asimétrico. Cualquier combinación es posible, siempre y cuando tengamos al menos un puerto destinado a cada 
dirección. De esta forma, \redborderddos{} es completamente escalable desde un punto de vista de admisión de datos.

\subsection{Registro y alerta del ataque. El protocolo Apache Kafka}
% TODO ver formato del registro: Disco duro y por kafka
Cuando un ataque se produce, \redborderddos{} es capaz de registrarlo en un fichero de texto plano del disco duro y 
enviarlo por la plataforma Apache Kafka\index{Apache Kafka}.

Apache Kafka es un protocolo de transferencia de mensajes que sigue un modelo de intercambiador o 
\emph{broker}\index{Kafka Broker}. Está diseñado para ser distribuido y extensible \cite{ApacheKafka}, por lo que si 
encontramos mucha carga de trabajo, es posible aumentar, de manera horizontal\footnote{Esto es, doblar el número de 
nodos debe doblar, aproximadamente, el rendimiento obtenido.}, la capacidad de procesamiento, siempre y cuando 
dispongamos de máquinas (reales o virtuales) que sirvan de nodos Kafka.

Así, \redborderddos{} es un productor Kafka\index{Productor Kafka}, que envía el registro de ataques a una cola de 
mensajes a un \emph{broker}, que los almacenará y entregará al consumidor\index{Consumidor Kafka} que los solicite.

Muchos sistemas de procesamiento de eventos usan Apache Kafka como base para su funcionamiento. Por ejemplo, es posible 
enriquecer los eventos con Apache Storm\index{Apache Storm} \cite{ApacheStorm}, o bien almacenarlos en una base de 
datos orientada a documentos como MongoDB\index{MongoDB} \cite{MongoDB}, mucho más rápida a la hora de almacenar este 
tipo de eventos que las bases de datos relacionales usadas tradicionalmente.

\subsection{Mitigación del ataque}
Para mitigar el ataque, es necesario que exista un cortafuegos\index{Cortafuegos} o un \gls{IPS}\index{Intrusion 
Prevention System} que bloquee el tráfico dirigido al activo a proteger. Una vez que éste existe, es necesaria una vía 
de comunicación con el mismo. Actualmente, \redborderddos{} simplemente alerta de los ataques, por lo que sería 
necesario que el \gls{IPS} o algún sistema intermedio leyese de la cola Kakfa y modificase su comportamiento en base a 
dicha lectura.

\section{Estructura general}\LABSEC{EsctructuraGeneral}
Internamente, \redborderddos{} intenta aprovechar al máximo la potencia de procesamiento del sensor, haciendo todas las 
tareas posibles de una manera concurrente.

Para ello, separaremos en distintos núcleos\footnote{Entendidos como núcleos de procesadores físicos.} del sensor los 
distintos bloques funcionales en los que se divide el proyecto, representados en la figura \FIG{diagramaActividad}. A 
saber:

\begin{description}
 \item [Clúster] La función del clúster es agrupar los paquetes entrantes y salientes de las distintas 
interfaces, indicar el sentido del mismo, y dirigirlos a las distintas colas que los sub-contadores leen.
 \item [Sub-contadores] Los sub-contadores agrupan todos los paquetes entrantes por flujos según IP externa, y 
contabilizan los distintos valores necesarios para ejecutar el algoritmo \gls{CUSUM} por cada flujo.
 \item [Contador Maestro y Decisor] El contador maestro, cada periodo de tiempo definido, recoge los contadores de cada 
sub-contador y aplica el algoritmo \gls{CUSUM} sobre ellos. Por su parte, el decisor se encarga de comparar dichos 
valores con los valores límite, identificando la IP como atacante si encontramos que una de ellas los sobrepasa.
\end{description}

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{CapituloEstructura/Figuras/DiagramaFlow-crop}
\caption{Diagrama de Actividad de \redborderddos}
\LABFIG{diagramaActividad}
\end{figure}
%

\subsection{Clúster}\index{PF\_RING Cluster}\LABSSEC{EstructuraCluster}
Un clúster \acrshort{PFRING}\footnote{En el capítulo \CHAP{@TODO} se detallará qué es \acrshort{PFRING}. Por el 
momento, es sólo el nombre concreto de este tipo de clúster.} es capaz de dividir todo el troncal de tráfico recogido 
por una o varias interfaces en una o más colas, de forma que cada cola vea sólo una porción del tráfico, de una manera 
coherente.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.75\textwidth]{CapituloEstructura/Figuras/Cluster-crop}
\caption{Funcionamiento del clúster}
\LABFIG{Cluster}
\end{figure}
%

La función de distribución es completamente definible: Podríamos haber decidido enviar los paquetes en 
\emph{round-robbin}, esto es, uno a cada cola cada vez.

La forma de reenvío que hemos elegido es por tupla (\emph{IP origen},\emph{IP destino}) de manera simétrica, esto es, 
la petición y la respuesta de un mismo flujo siempre irá dirigido a la misma cola. De esta forma, como se verá más 
adelante, cada hilo contador (ver \SSEC{subcontadores}) sólo ve una parte del flujo coherente, y el contador maestro, a 
la hora de agrupar todos los flujos, tendrá que hacer muchas menos operaciones, ya que nunca se tendrán que sumar dos 
registros.

Por otra parte, la función de distribución marcará el paquete como entrante o saliente, según haya llegado por una 
interfaz definida como tal.

Al multiplexar de esta forma las colas, conseguimos reducir el número de inter-bloqueos, ya que en 
logar de tener un modelo en el que muchos hilos atacan una misma cola, cada hilo sólo mirará su propia cola,, y en cada 
cola sólo podrán actuar dos bloqueantes (el cluster y el hilo).

De esta forma, conseguimos transparencia y escalabilidad en el número de interfaces de entrada de datos, e 
incrementamos el rendimiento a la hora de agrupar los paquetes.

Se puede ver el gráficamente el algoritmo seguido por la función de distribución en el diagrama de actividad de la 
\FIG{ActividadDistribFunc}.

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{CapituloEstructura/Figuras/ActividadFuncionDistribucionCluster-crop}
\caption{Función de distribución}
\LABFIG{ActividadDistribFunc}
\end{figure}
%

\subsection{Subcontadores}\index{Subcontador}\LABSSEC{subcontadores}
\subsubsection{Estructura contador}
Con el fin de almacenar las características del tráfico descritas en \SSEC{Parametros de interés}, se prepara una 
estructura de datos en la que se irán contando los paquetes y octetos de cada tipo. Dicha estructura de datos puede 
verse en \lstlistingname{} \ref{code:RbCounter}. Por comodidad, dicha estructura también será llamada, a lo largo del 
proyecto, simplemente \texttt{RbCounter}.

\begin{lstlisting}[language=C++,caption={Estructura de contadores por flujo}, breaklines=true, 
label=code:RbCounter,numbers=left,float=htbp]
typedef uint32_t counter_t;

typedef struct rb_counters_s{
    rb_addr_t external_address; ///< External IP address

    counter_t tcp_pkts;     ///< number tcp packets in the flow
    counter_t udp_pkts;     ///< number udp packets in the flow
    counter_t icmp_pkts;    ///< number icmp packets in the flow
    counter_t total_pkts;   ///< total number packets in the flow

    counter_t tcp_bytes;    ///< tcp bytes in the flow
    counter_t udp_bytes;    ///< udp bytes in the flow
    counter_t icmp_bytes;   ///< icmp bytes in the flow
    counter_t total_bytes;  ///< total bytes in the flow

    counter_t input_pkts;   ///< Input packets in the flow;
    counter_t output_pkts;  ///< Output packets in the flow;
    counter_t input_bytes;  ///< Input bytes in the flow;
    counter_t output_bytes; ///< Output bytes in the flow;

    counter_t syn_counter;      ///< Number of tcp packets with syn flag enabled
    counter_t syn_ack_counter;  ///< Number of tcp packets with syn+ack flags enabled

    /// Node iterator to store and recover for hashtable node.
    tommy_hashtable_node hashtable_node;
} rb_counters_t;
\end{lstlisting}

\subsubsection{Pool de contadores}\LABSSSEC{Pool de contadores}
Los sub-contadores son los encargados de contar las distintas características de los flujos de tráfico, y deben 
hacerlo de una forma muy rápida para evitar que el tráfico se acumule.

Por ello, necesitan:
\begin{itemize}
 \item Memoria suficiente para almacenar las características de cada flujo independiente
 \item Una forma eficiente de localizar, en la memoria reservada anteriormente, el contador asociado a cada flujo.
\end{itemize}

Un Pool o Piscina de Contadores\index{Piscina de Contadores}, llamado en el código \emph{Counters Pool} es una 
estructura capaz de almacenar y organizar los contadores basándose en su dirección IP externa, según venga por la 
interfaz definida como entrante o saliente.

Consta de dos sub-clases:
\begin{itemize}
 \item Una gran pila de contadores, a la cual se le puede pedir nuevos contadores (\emph{push}) o bien los que ya 
contiene (\emph{pop}).
 \item Una tabla HASH, cuya clave es la dirección IP externa, para localizar eficientemente los contadores 
anteriormente almacenados en función del flujo al que pertenezca.
\end{itemize}

En \FIG{ClasesPoolContadores} podemos ver el diagrama de clases asociado a esta estructura\footnote{Si bien C no es un 
lenguaje orientado a objetos, sigue siendo capaz de encapsular comportamiento, por lo que podemos hablar de clases 
con métodos públicos y atributos ocultos o no accesibles.}.

%TODO describir rbAddr

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{CapituloEstructura/Figuras/DiagramaClasesContadores-crop}
\caption{Diagrama de clases de la piscina de contadores}
\LABFIG{ClasesPoolContadores}
\end{figure}
%

A lo largo de la ejecución del programa, no se permitirá hacer nuevas reservas de memoria al \gls{SO} para 
nuevos contadores. En el caso de ataque, esto saturaría los recursos de los que dispone la máquina, por lo que tiene 
sentido ponerle un límite superior. Por otro lado, en caso de ataque repentino, no se debería perder tiempo en llamadas 
al \gls{SO} para pedir más memoria. Así pues, se dispondrá de un número limitado de contadores desde el inicio hasta el 
final de la ejecución del programa.

\subsubsection{Algoritmo del subcontador}
Tras ser enviado el paquete a una cola, le tocará ser procesado por un hilo contador. Cada hilo contador tiene 
asociadas dos piscinas de contadores\footnote{ver \SSSEC{Pool de contadores}.}. 

Cuando un nuevo paquete llega, la Función de Distribución\footnote{ver \SSEC{EstructuraCluster}.} lo habrá marcado como 
entrante o saliente, según la interfaz por la que ha entrado al Cluster. A partir de ahí, se extrae su \gls{IP} externa 
mediante el Algoritmo \ALG{ExtracciónIPExterna}.

\begin{algorithm}[htbp]
 \KwData{Paquete a analizar}
 \KwResult{Dirección del mismo }
 \eIf{paquete entrante}{
   ip externa $\gets$ ip origen\;
   }{
   ip externa $\gets$ ip destino\;
  }
 \caption{Algoritmo de extracción de IP externa}
 \LABALG{ExtracciónIPExterna}
\end{algorithm}

Tras ello, se pide a la piscina de contadores el contador asociado a la IP externa, y se actualiza la información 
pertinente, controlando siempre los errores como que la piscina esté llena y no pueda albergar ningún contador más.

En la \FIG{ActividadSubcontador} podemos ver el diagrama de actividad de esta función.

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{CapituloEstructura/Figuras/ActividadFuncionContador-crop}
\caption{Función de sub-contador}
\LABFIG{ActividadSubcontador}
\end{figure}
%

\subsection{Contador Maestro}\index{Contrador Maestro}
\subsubsection{Señal SIGALRM}\index{SIGALRM}
Para conseguir que la función del contador maestro se ejecute de una manera periódica, se usa la señal 
SIGALRM\index{Señales de GNU/Linux}\index{SIGALRM} de GNU/Linux (ver sección \SSEC{SIGALRM}). Cuando esta se produce, 
se activará una variable global \texttt{sigalrm\_received} y, si esta ya estaba activada en el momento que se produjo, 
se activará también \texttt{sigalrm\_accum}, como indicador de que \redborderddos{} no es capaz de procesar todo el 
flujo de tráfico.

\subsubsection{Mínima interrupción de los sub-contadores}
Los sub-contadores son la parte de \redborderddos que más carga de trabajo llevan. Es por eso por lo que se ha enfocado 
todo el diseño de la aplicación en hacerlos lo más escalable posible.

Sin embargo, es necesario recolectar los contadores y procesarlos en algún momento, con el fin de extraer los distintos 
estadísticos \gls{CUSUM}. Sería impensable bloquear los sub-contadores con el fin de extraer dichos estadísticos: Si la 
piscina está muy ocupada, la cola de paquetes se llenaría y nos veríamos obligados a tirar paquetes.

Para evitar detener los hilos sub-contadores un largo periodo de tiempo, se trabaja con punteros y con las variables 
cerrojo de la librería \gls{pthreads}\index{Librería pthread}. Cada hilo contador tiene reservados dos piscinas de 
contadores, y sólo usa en un periodo de tiempo una de ellas, que va llenando de contadores. Un puntero apunta al 
contador que está usando actualmente, situado en un vector que llamaremos \emph{Piscina Contadores}. Así, el contador 
que está usando el trabajador \emph{i} actualmente será \emph{Piscina contadores[i]}.

Cada hilo contador tiene asociado una variable cerrojo\index{Variable Cerrojo}, que bloquea cuando trabaja con su 
piscina. Cuando se activa la alarma del hilo principal, éste último bloquea dicha variable, e intercambia las piscinas 
de los hilos contadores, lo que se traduce en una simple asignación de punteros y esto, a su vez, se traduce como un 
tiempo mínimo de bloqueo.

Así pues, en el instante previo al lanzamiento de la alarma, el hilo contador ve una piscina llena de contadores, 
mientras que en el instante posterior ve una piscina nueva y limpia en la que almacenar. Para una descripción 
gráfica, ver \FIG{AntesSIGALRM} y \FIG{DespuesSIGALRM}.

\begin{figure}[htbp]
\centering
%\hfill
\subfloat[Instante antes de lanzar SIGALRM]%
   {\LABFIG{AntesSIGALRM}%
   \includegraphics[width=0.45\textwidth]{CapituloEstructura/Figuras/DiagramaPoolsAntesSIGALRM-crop}}%
\hfill
\subfloat[Instante después de lanzar SIGALRM]%
 {\LABFIG{DespuesSIGALRM}%
 \includegraphics[width=0.45\textwidth]{CapituloEstructura/Figuras/DiagramaPoolsDespuesSIGALRM-crop}}%

\caption{Estado de las piscinas de contadores instantes antes y después de lanzar SIGALRM}
%\LABFIG{ActividadSubcontador}
\end{figure}
%

\subsubsection{Extración de estadísticos CUSUM}\LABSSSEC{ExtraccionEstadisticosCUSUM}

Tras intercambiar los contadores con el/los hilos contadores, el hilo maestro deberá extraer las estadísticas CUSUM de 
los mismos. Para ello, preparamos una estructura de datos con los parámetros de interés vistos en la 
\SSEC{Parametros de interés}. Por ello, de cada contador IP se debe extraer una muestra $x_i$ que indique el estado de 
las variables a controlar en ese momento.

Por comodidad, copiamos la estructura en \lstlistingname{} \ref{code:RbCusumStats}, y el algoritmo seguido para 
rellenarla en las ecuaciones desde \EQ{ExtractCusumTcpBytesRate} hasta \EQ{ExtractCusumInputOutputRate}.

\begin{align}
 \text{stats.tcp\_bytes\_percent}  &\gets \frac{\text{counters.tcp\_bytes   }}{\text{counters.total\_bytes}}
                                                                                    \LABEQ{ExtractCusumTcpBytesRate}\\
 \text{stats.udp\_bytes\_percent}  &\gets \frac{\text{counters.udp\_bytes   }}{\text{counters.total\_bytes}}\\
 \text{stats.icmp\_bytes\_percent} &\gets \frac{\text{counters.icmp\_bytes  }}{\text{counters.total\_bytes}}\\
%
 \text{stats.tcp\_pkts\_percent}   &\gets \frac{\text{counters.tcp\_pkts    }}{\text{counters.total\_pkts}}\\
 \text{stats.udp\_pkts\_percent}   &\gets \frac{\text{counters.udp\_pkts    }}{\text{counters.total\_pkts}}\\
 \text{stats.icmp\_pkts\_percent}  &\gets \frac{\text{counters.icmp\_pkts   }}{\text{counters.total\_pkts}}\\
%
 \text{stats.syn\_ack\_rate}       &\gets \frac{\text{counters.syn\_counter }}{\text{counters.ack\_counter}}\\
 \text{stats.input\_output\_prate} &\gets \frac{\text{counters.input\_pkts  }}{\text{counters.output\_pkts}}\\
 \text{stats.input\_output\_brate} &\gets \frac{\text{counters.input\_bytes }}{\text{counters.output\_bytes}}
                                                                                     \LABEQ{ExtractCusumInputOutputRate}
\end{align}

\begin{lstlisting}[language=C++,caption={Estructura estadísticos CUSUM}, breaklines=true, 
label=code:RbCusumStats,numbers=left,float=htbp]
typedef struct rb_cusum_stats_sample_s{
    double tcp_bytes_percent;   ///< TCP bytes/total bytes rate
    double udp_bytes_percent;   ///< UDP bytes/total bytes rate
    double icmp_bytes_percent;  ///< ICMP bytes/total bytes rate

    double tcp_pkts_percent;    ///< TCP paktes/total packets rate
    double udp_pkts_percent;    ///< UDP paktes/total packets rate
    double icmp_pkts_percent;   ///< ICMP paktes/total packets rate

    double syn_ack_rate;        ///< syn/ack rate

    double input_output_prate;   ///< Rate input/output packets
    double input_output_brate;   ///< Rate input/output bytes
}rb_cusum_stats_sample_t;
\end{lstlisting}

\subsubsection{Muestra completa de un estadístico CUSUM}
Como vimos en la \SEC{AlgoritmoCUSUM}, es necesario llevar el algoritmo CUSUM para el lado positivo y negativo ($C_i^+$ 
y $C_i^-$). Por tanto, con cada muestra debemos actualizar dos estadísticos \gls{CUSUM} por flujo o \gls{IP} externa.

Por ello, se debe crear una estructura que nos permita relacionar esas tres características. En cada ciclo del contador 
maestro, éste extraerá los contadores de los \texttt{CountersPool} vistos en \SSSEC{Pool de contadores} usando el 
método \texttt{popCounter} hasta que no haya más contadores (esto es, hasta que la misma devuelve \texttt{NULL}.

Por cada contador, extraemos una muestra $X_i$ como hemos visto en el \SSSEC{ExtraccionEstadisticosCUSUM}. Tras ello, 
aplicamos el algoritmo visto en la \SEC{AlgoritmoCUSUM}:

\begin{align}
 C_i^+ &= \max \left[0,\left\{C_{i-1}^+\left(x_i-\mu_0\right)\right\}-K\right] \\
 C_i^- &= \max \left[0,\left\{C_{i-1}^-\left(x_i-\mu_0\right)\right\}-K\right]
\end{align}

Donde $C_{i-1}$ es el contador almacenado en la anterior iteración.

No obstante, existe un problema con esta forma de actuar: es posible que en una iteración exista el $x_i$ de un 
contador, en la siguiente iteración no exista tráfico de esa dirección \gls{IP}, por lo que no se generaría ningún 
contador del mismo, y vuelva a existir el contador en la tercera iteración. De esa forma, si $T=-\mu_0-K$, $C_3$ 
quedaría:
\begin{align}
 C_3 = \max\left[0,C_1 + (x_3-T)\right] = \max\left[0,x_1-T+x_3-T\right] = 
       \max\left[0,x_1+x_3-2T\right] 
\end{align}
Sin embargo, al tener en cuenta $X_2=0$, $C_3$ debería quedar:
\begin{align}
 C_3 &= \max\left[0,C_1 + C_2 + (x_3-T)\right] = \max\left[0,x_1-T+0-T+x_3-T\right]
     =        \max\left[0,x_1 + x_3 -3T\right] 
\end{align}

Para salvar esa diferencia, tenemos dos opciones:
\begin{itemize}
 \item Escanear todo el espacio de direcciones CUSUM y actualizarlo.
 \item Almacenar, por cada CUSUM que se actualice, la marca de tiempo en la que fue actualizado.
\end{itemize}

Se elige, por razones de rendimiento, la segunda opción. Por tanto, la estructura para almacenar $C_i^+$ y $C_i^-$ 
quedan como se muestra en la \FIG{ClasesCusumSample}.

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{CapituloEstructura/Figuras/DiagramaClasesCusumSample-crop}
\caption{Diagrama de clases de las estructuras de almacenamiento de estadísticas CUSUM}
\LABFIG{ClasesCusumSample}
\end{figure}
%

Como funciones especiales que actúan sobre la estructura, se destacan \emph{iteration}, que realiza una iteración 
\gls{CUSUM} sobre la muestra, y \emph{cmp}, que guarda en una estructura del mismo tipo la comparación entre dos 
estructuras, aplicando el la comparación vista en Algoritmo\ALG{ComparacionFlotante} en cada miembro de la misma.

\subsubsection{Limpieza de estadísticos antiguos}
Todo lo que se aprende, debe ser olvidado. Si pretendiésemos almacenar estadísticas \gls{CUSUM} por cada \gls{IP} que 
vemos indefinidamente, terminaríamos por saturar los contadores, y no podríamos seguir el comportamiento de ninguna 
dirección \gls{IP} más.

Por el momento, se reservará una cantidad fija de memoria para los estadísticos \gls{CUSUM}, y se almacenarán, a 
priori, en una lista de contadores \emph{libres}. A medida que se van necesitando, se almacenarán en otra lista de 
contadores \emph{en uso}. Es importante, desde el punto de vista del rendimiento, que la entrada de contadores en esta 
lista esté bien definida: O bien por la cabeza, o bien por la cola. A lo largo de este ejemplo, la entrada de 
estadísticos \gls{CUSUM} nuevos se realizará por la cabeza.

A intervalos de tiempo regulares, se realizará una limpieza de los contadores usados, comenzando por el lado inverso a 
la entrada de los mismos. En este ejemplo, el sentido elegido será la cola. Se elegirá un tiempo mínimo, a partir del 
cual, si el estadístico no ha sido actualizado tras esa marca de tiempo, será eliminado de la lista de 
estadísticos \emph{en uso} y pasará a la lista de \emph{libres}. Podemos ver este procedimiento en el 
Algoritmo\ALG{EliminacionContadoresAntigos} y en la \FIG{DiagramaActividadLimpiarLista}.

\begin{algorithm}
 \KwData{Lista de estadísticos cusum $l$, marca de tiempo $t$}
 \KwResult{Lista de estadísticos con sólo las entradas con marca de tiempo $t_0$ que cumplen $T_0>t$}
 \While{element $e \gets l.\text{last} y e.timestamp < t_0 $}{
	 usados.delete($e$)\;
	 libres.push($e$)\;
 }
 \caption{Procedimiento para la eliminación de contadores antiguos}
 \LABALG{EliminacionContadoresAntigos}
\end{algorithm}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.4\textwidth]{CapituloEstructura/Figuras/ActividadFuncionLimpiarPoolCUSUM-crop}
\caption{Diagrama de actividad de la limpieza de estadísticos CUSUM antiguos}
\LABFIG{DiagramaActividadLimpiarLista}
\end{figure}
%

El orden de entrada y salida en la segunda lista no es relevante, si bien es preferible que esta actúe como una pila, 
con el fin de maximizar las probabilidades de que la memoria ocupada por los contadores se encuentre en la caché del 
procesador\footnote{Dicha caché eliminará las páginas que no han sido recientemente utilizadas. Si queremos volver a 
ellas, será necesario volver a recuperarlas de la RAM.}.

Cuando se use de nuevo un contador de la lista de contadores \emph{en uso}, esto es, se insertó en $C_i$ y se usó en 
$C_j j>i$, es necesario volver a colocarlo en la cabeza de la lista. Para ello, se deberá extraer de la misma, y volver 
a colocar en la cabeza. Si no se hiciese este paso, las marcas de tiempo de cada contador no estarían ordenadas en la 
lista, y la limpieza no sería efectiva.

Por ejemplo, si tenemos cinco flujos que están activos en un tiempo $t_i$, y nunca más vuelven a estar activos. Tras 
ellos, y sin haberse olvidado aún, llega un flujo en el instante $t_j j>i$ que, por ejemplo, se trata de un proceso 
automatizado que hace peticiones en un corto espacio de tiempo (por tanto, nunca olvidaremos ese flujo, ya que nunca 
será lo suficientemente antiguo).

Si no actualizamos la posición del elemento que ha llegado en $t_j$, y lo volvemos a colocar en la cabeza de la lista, 
nunca eliminaremos los elementos que llegaron antes.

\subsubsection{Pool de estadísticos CUSUM}

Al igual que ocurre con los contadores, el contador maestro necesita almacenar los diferentes estadísticos CUSUM que ha 
ido almacenando a lo largo del tiempo, y recuperarlos de una manera rápida. Para ello, se utiliza una estructura 
similar a la usada para almacenar y localizar los contadores: un Pool de estadísticos CUSUM.

Para ello, se utiliza una estructura similar a la vista en el \SSSEC{Pool de contadores}, pero necesita algunas 
diferencias:
\begin{itemize}
 \item 
\end{itemize}


\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{CapituloEstructura/Figuras/DiagramaClasesCUSUM-crop}
\caption{Diagrama de clases de la piscina de estadísticas CUSUM}
\LABFIG{ClasesCusumPool}
\end{figure}
%

\subsection{Decisor}\index{Decisor}
Periódicamente, el contador maestro recogerá.


\section{Resúmenes}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{Resumen}[Resumen de la estructura]
\subsection*{S1}
\end{Resumen}

